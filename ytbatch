#!/usr/bin/env bash
# Improved yt-dlp batch downloader
#
# Improvements:
# - safer bash options (set -euo pipefail)
# - command-line flags for base dir, parallelism, dry-run, and log file
# - robust fallback if GNU parallel is missing (uses xargs / background jobs)
# - better channel/name detection with sensible fallbacks
# - safe filenames including video id to avoid collisions
# - yt-dlp options for resuming, retries, polite rate limiting, and archive file
# - logging with timestamps and exit trap
# - avoids concurrent runs with flock
# - looks for channels file in ~/.config/ytbatch/channels and creates one with examples if missing
#
# Usage: yt-dlp_download [-n|--dry-run] [-b base_dir] [-j jobs] [-l log_file] [channels_file]

set -euo pipefail
IFS=$'\n\t'

PROG_NAME="$(basename "$0")"
DEFAULT_BASE_DIR="${BASE_DIR:-$HOME/Videos}"
DEFAULT_JOBS="${MAX_PARALLEL_DOWNLOADS:-4}"
DEFAULT_LOG_FILE="$DEFAULT_BASE_DIR/script.log"

DRY_RUN=0
BASE_DIR="$DEFAULT_BASE_DIR"
JOBS="$DEFAULT_JOBS"
LOG_FILE="$DEFAULT_LOG_FILE"

print_help() {
    cat <<EOF
Usage: $PROG_NAME [options] [channels_file]

Options:
  -n, --dry-run        Print what would be done but don't download
  -b DIR, --base DIR   Base directory to store downloads (default: $DEFAULT_BASE_DIR)
  -j N, --jobs N       Number of parallel downloads (default: $DEFAULT_JOBS)
  -l FILE, --log FILE  Log file (default: $DEFAULT_LOG_FILE)
  -h, --help           Show this help and exit

If channels_file is not provided, the script will look for:
  ${XDG_CONFIG_HOME:-$HOME/.config}/ytbatch/channels
and will create it with example entries if it doesn't exist.
EOF
}

# simple getopt/args parsing
ARGS=()
while (( "$#" )); do
  case "$1" in
    -n|--dry-run) DRY_RUN=1; shift ;;
    -b|--base) BASE_DIR="$2"; shift 2 ;;
    -j|--jobs) JOBS="$2"; shift 2 ;;
    -l|--log) LOG_FILE="$2"; shift 2 ;;
    -h|--help) print_help; exit 0 ;;
    --) shift; break ;;
    -*|
      echo "Unknown option: $1" >&2
      print_help
      exit 1 ;;
    *)
      ARGS+=("$1"); shift ;;
  esac
done
# restore positional parameters
set -- "${ARGS[@]}"

# Determine channels file: either provided as positional arg, or use config default
if [ $# -ge 1 ]; then
    CHANNELS_FILE="$1"
else
    CONFIG_DIR="${XDG_CONFIG_HOME:-$HOME/.config}/ytbatch"
    DEFAULT_CHANNELS_FILE="$CONFIG_DIR/channels"
    if [ -f "$DEFAULT_CHANNELS_FILE" ]; then
        CHANNELS_FILE="$DEFAULT_CHANNELS_FILE"
    else
        mkdir -p "$CONFIG_DIR"
        cat > "$DEFAULT_CHANNELS_FILE" <<'EXAMPLES'
# ytbatch channels file
# Add one YouTube channel, playlist, or video URL per line.
# Lines starting with # are comments.
#
# Examples (replace with channels/playlists you want to download):
https://www.youtube.com/c/Veritasium
https://www.youtube.com/c/TED
https://youtu.be/dQw4w9WgXcQ
# End of examples
EXAMPLES
        chmod 600 "$DEFAULT_CHANNELS_FILE"
        CHANNELS_FILE="$DEFAULT_CHANNELS_FILE"
        echo "Created example channels file at $DEFAULT_CHANNELS_FILE"
    fi
fi

# ensure yt-dlp installed
if ! command -v yt-dlp >/dev/null 2>&1; then
    echo "yt-dlp is not installed. Please install it before running this script." >&2
    exit 1
fi

# check for flock (used to avoid concurrent runs)
if ! command -v flock >/dev/null 2>&1; then
    FLOCK_AVAILABLE=0
else
    FLOCK_AVAILABLE=1
fi

# detect parallel; if missing we'll fallback
if command -v parallel >/dev/null 2>&1; then
    HAS_PARALLEL=1
else
    HAS_PARALLEL=0
fi

mkdir -p "$BASE_DIR"
touch "$LOG_FILE"

log() {
    local ts msg
    ts="$(date '+%Y-%m-%d %H:%M:%S')"
    msg="$1"
    printf '%s - %s\n' "$ts" "$msg" | tee -a "$LOG_FILE"
}

# temporary channels list and cleanup
TMP_CHANNELS="$(mktemp)"
cleanup() {
    local rc=$?
    rm -f "$TMP_CHANNELS" || true
    log "Script exiting (status=$rc)."
}
trap cleanup EXIT

# remove empty lines and comments from the input file before processing
awk 'NF && $1 !~ /^#/ { gsub(/\r/,"\"); print }' "$CHANNELS_FILE" > "$TMP_CHANNELS" || true

# URL validation: more permissive but restrict to youtube domains or youtu.be
is_valid_url() {
    local url="$1"
    # accept http(s) and youtu.be plus youtube domains and handles
    case "$url" in
        http://*|https://*)
            if echo "$url" | grep -qiE '(^|//)(www\.)?(youtube\.com|youtu\.be|youtube-nocookie\.com)'; then
                return 0
            fi
            ;;
        youtu.be/*)
            return 0
            ;;
    esac
    return 1
}
export -f is_valid_url

# sanitize a string to safe dir name
sanitize() {
    local s="$1"
    # replace non-alnum with underscore, collapse multiples, trim underscores
    s="$(echo "$s" | sed 's/[^A-Za-z0-9._-]/_/g' | sed 's/_\+/_/g' | sed 's/^_//; s/_$//')"
    printf '%s' "$s"
}

# derive a channel name with fallbacks
generate_channel_name() {
    local url="$1"
    local name
    # Try channel first, then uploader, then fallback to hostname + path
    name="$(yt-dlp --no-warnings --skip-download --get-filename -o '%(channel)s' "$url" 2>/dev/null | head -n1 || true)"
    if [ -z "$name" ]; then
        name="$(yt-dlp --no-warnings --skip-download --get-filename -o '%(uploader)s' "$url" 2>/dev/null | head -n1 || true)"
    fi
    if [ -z "$name" ]; then
        # As final fallback, use parsed url host/path
        name="$(echo "$url" | sed -E 's#https?://##; s#[/?#].*##; s/:/_/g')"
    fi
    sanitize "$name"
}

# download function for one URL
download_channel() {
    local url="$1"
    if [ -z "$url" ]; then
        return 0
    fi

    if ! is_valid_url "$url"; then
        log "Skipping invalid URL: $url"
        return 0
    fi

    local channel_name channel_dir date_dir archive_file out_template
    channel_name="$(generate_channel_name "$url")"
    if [ -z "$channel_name" ]; then
        log "Could not determine channel name for $url — skipping"
        return 0
    fi

    channel_dir="$BASE_DIR/$channel_name"
    mkdir -p "$channel_dir" || { log "Failed to create channel dir: $channel_dir"; return 1; }

    date_dir="$channel_dir/$(date +%Y-%m-%d)"
    mkdir -p "$date_dir" || { log "Failed to create date dir: $date_dir"; return 1; }

    archive_file="$channel_dir/downloaded_videos.txt"
    # include video id in filename to avoid duplicates, and keep original extension
    out_template="$date_dir/%(upload_date)s - %(title)s [%(id)s].%(ext)s"

    log "Starting download for '$channel_name' from $url (archive: $archive_file)"

    if [ "$DRY_RUN" -eq 1 ]; then
        log "[DRY RUN] yt-dlp --no-overwrites --continue --download-archive \"$archive_file\" -o \"$out_template\" \"$url\""
        return 0
    fi

    # Run yt-dlp with polite defaults and retries
    yt-dlp \
        --no-overwrites \
        --continue \
        --download-archive "$archive_file" \
        --retries 10 \
        --fragment-retries 10 \
        --sleep-interval 2 \
        --max-sleep-interval 10 \
        --no-warnings \
        -o "$out_template" \
        "$url" >> "$LOG_FILE" 2>&1

    rc=$?
    if [ $rc -ne 0 ]; then
        log "yt-dlp failed for $channel_name (rc=$rc). See $LOG_FILE for details."
        return $rc
    else
        log "Completed downloads for $channel_name."
        return 0
    fi
}
export -f download_channel
export BASE_DIR LOG_FILE DRY_RUN

# Acquire a lock to avoid concurrent script runs (if flock available)
LOCK_FD=200
LOCK_FILE="$BASE_DIR/yt-dlp_download.lock"
exec {LOCK_FD}>
"$LOCK_FILE" || true
if [ "$FLOCK_AVAILABLE" -eq 1 ]; then
    flock -n "$LOCK_FD" || { log "Another instance is running (could not lock $LOCK_FILE). Exiting."; exit 1; }
    # ensure the script releases lock on exit (shell will close fd)
fi

log "Starting download process (jobs=$JOBS, dry-run=$DRY_RUN)..."

# Use GNU parallel if available, otherwise fallback
if [ "$HAS_PARALLEL" -eq 1 ]; then
    parallel --will-cite -a "$TMP_CHANNELS" -j "$JOBS" --line-buffer download_channel {}
else
    log "GNU parallel not found — falling back to xargs / background jobs."
    if command -v xargs >/dev/null 2>&1; then
        # xargs -P supports parallelism; ensure it treats each line as a single argument
        cat "$TMP_CHANNELS" | xargs -d '\n' -n 1 -P "$JOBS" -I {} bash -c 'download_channel "$@"' _ {}
    else
        # final fallback: background + job control
        while IFS= read -r url || [ -n "$url" ]; do
            # wait until subprocesses less than JOBS
            while [ "$(jobs -rp | wc -l)" -ge "$JOBS" ]; do
                sleep 0.5
            done
            download_channel "$url" &
        done < "$TMP_CHANNELS"
        wait
    fi
fi

log "Download process completed."
exit 0
